%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]pages
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan,screen]{acmart}
%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{DDoS defence mechanisims }

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Alexander Haar}
\email{Haaralexander3@gmail.com}
\affiliation{%
  \institution{Universität Kassel}
  \city{Kassel}
  \state{Hessen}
  \country{Deutschland}
}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Abstract TBD
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Source Address Validation, IP Spoofing, IXP, Scrubber, Machine Learning}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Cyberkriminalität ist in der modernen Gesellschaft nicht mehr wegzudenken. Insbesondere die DDoS Attacken gegen Unternehmen und staatliche Institutionen haben in den letzten Jahren dramatisch zugenommen.

\section{IXP Scrubber}
Zuerst wird erklärt was ein Internet Exchange Point (IXP) ist und wo er sich im Internet befindet. Danach erfolgt eine Einführung in den IXP Scrubber, wie er funktioniert und wie er es schafft schädlichen Internetverkehr zu filtern.

\subsection{Internet Exchange Point}
Das Internet besteht aus einer Vielzahl von miteinander verbundenen Netzwerken. Um diese Netzwerke effizient zu verknüpfen, werden sogenannte Internet Exchange Points (IXPs) am Rand dieser platziert. Die IXPs fungieren als zentrale Knotenpunkte im Internet und ermöglichen es, den Internetverkehr von einem Netzwerk auf ein anderes zu leiten. Praktisch betrachtet handele es sich bei IXPs um Schaltstellen, die als Bindeglieder zwischen verschiedenen Netzwerken dienen. Daraus folge, dass durch einen IXP sehr viel Internetverkehr durch laufe.

Die Funktionsweise eines IXPs könne mit der eines Internet-Switches verglichen werden, wobei dieser auf der zweiten Ebene des OSI-Modells positioniert sei. Zur Kommunikation mit einem IXP verwenden Netzwerke das sogenannte Backbone-Protokoll.

Ein wesentlicher Vorteil von einem IXP liege in der geringen Latenz und der kurzen Roundtrip-Zeit. Darüber hinaus ermögliche es ein IXP, den Verkehr im Falle eines Ausfalls auf alternative Routen umzuleiten, was die Robustheit des Netzwerks erhöhe. Dies trage dazu bei, dass das Netzwerk weniger anfällig für Fehler und Störungen sei. \cite{ixp00}

\subsection{IXP Scrubber}
Der IXP Scrubber, im Folgenden als "Scrubber" bezeichnet, werde innerhalb eines Internet Exchange Points (IXP) eingesetzt. Seine Hauptaufgabe sei es, bösartigen Internetverkehr zu erkennen und herauszufiltern. Der Scrubber basiere auf einem Machine Learning System (MLS). Die primäre Motivation hinter diesem Scrubber sei die Abwehr von Distributed Denial of Service (DDoS) Attacken. DDoS Attacken seien besonders problematisch, da es Unternehmen gebe, bei denen der Kauf von Internetverkehr kostengünstig sei. Dies führe dazu, dass dieser Angriffsvektor häufig genutzt werde und das Volumen solcher Angriffe könne bis zu 3,5 Tbit/s erreichen.

Das MLS des Scrubbers bestünde aus zwei Hauptschritten. Zunächst erfolge das Training des Systems, gefolgt von der eigentlichen Klassifizierung der Daten. Der Grundgedanke des Scrubbers sei es, präzise zu arbeiten und gleichzeitig die Übersichtlichkeit zu wahren. Im Anschluss werde der Scrubber evaluiert.

\subsubsection{Microscopic Level}
Um zuverlässig zu funktionieren, brauche das Machine Learning System (MLS) viele Trainingsdaten. Aus diesem Grund seien dem MLS von fünf Partner Internet Exchange Points (IXPs) in Europa und den USA Daten zur Verfügung gestellt worden, die bis zu zwei Jahre alt sein konnten. Diese Daten seien in gutartigen und bösartigen Verkehr unterteilt. Der Internetverkehr, der automatisch vom System oder von benachbarten IXPs manuell als schädlich gekennzeichnet worden sei, erhielt das Label "blackholed". Verkehr mit diesem Label sei in ein "Schwarzes Loch" geleitet worden, was dazu geführt habe, dass sie verschwanden und das Ziel nicht beeinträchtigt worden sei. Durch die Verwendung des Border Gateway Protocol (BGP) seien diese Labels an andere IXPs weitergegeben worden. \cite{blackhole00}
Daten, die dieses Label nicht erhalten haben, seien als gutartig eingestuft worden. Die Trainingsmenge sei aus ungefähr dem gleichen Prozentsatz aus gutartigem und bösartigem Verkehr zusammengesetzt.

Auf den Trainingsdaten sei der Association Rule Mining (ARM) Algorithmus angewandt worden. ARM ist ein bekanntes Data-Mining-Verfahren, das Association-Regeln anhand der Daten in der Form A -> C lernt. Die Anwendung des Verfahrens auf den Testdaten habe 7859 Regeln ergeben. Anschließend seien alle Regeln eliminiert worden, die keinen Mehrwert hatten, weil sie eine zu geringe Konfidenz aufgewiesen hätten. Nach dieser Minimierung seien 367 Regeln übrig geblieben. Diese Anzahl sei gering genug gewesen, um es zu ermöglichen, die Regeln manuell zu überprüfen. In einem User Interface (UI) werden die Regeln angezeigt und Administratoren können zu den Regeln Kommentare hinzufügen sowie diese akzeptieren oder ablehnen.
Die zuvor gewonnen Regeln seien im nächsten Schritt unabhängig geprüft worden, damit überprüft werden konnte, dass sie keine Voreingenommenheit aufweisen und akkurat seien. Hierfür sei eine neue Testmenge erstellt worden, die als "Self Attack Set" (SAS) bezeichnet wurde. Das Wichtige bei diesen Testdaten sei es zu wissen, ob sie wahr oder falsch seien. Um dies zu garantieren, seien DDoS Attacken bei einem Unternehmen, wie Anfangs beschrieben, gekauft und auf einem speziell dafür ausgelegten und abgegrenzten Internetbereich ausgeführt worden. Zusätzlich sei gutartiger Internetverkehr ebenfalls simuliert und der SAS hinzugefügt worden.


In einem zusätzlichen Experiment, sei der ARM Algorithmus auf dem SAS ausgeführt worden. Die gewonnen Regeln seien von fünf Experten ausgewertet worden. Nach der Überprüfung seien 38 Regeln übrig geblieben. Im Anschluss sei gemessen worden, wie lange die Regeln benötigt haben und wie effektiv sie waren. Die Regeln haben eine kurze Laufzeit aufgewiesen und zeigten dabei eine hohe Effizienz auf. Es sei unter einem Prozent gutartiger Verkehr als bösartiger Verkehr gekennzeichnet und 75 Prozent des DDoS Verkehrs erfolgreich erkannt worden. Die Ergebnisse zeigen, dass der Ansatz eine gute Durchführbarkeit besitze.

\subsubsection{Microscopic Level}
Das Ziel des zweiten Schrittes sei es korrekt zu identifizieren, ob ein Ziel angegriffen werde oder nicht. Zusätzliche solle gelten, dass die Identifizierung ortsunabhängig sei und übersichtlich bleibe. Um dieses Ziel zu erreichen werden Kategorien gewichtet. Die Gewichtung finde vor der Klassifikation in der Vorverarbeitung statt. Kategorien, die häufig in blackhole Labels auftreten, würden eine positive Gewichtung erhalten, während Kategorien, die nicht in blackhole Labels auftreten, eine negative Gewichtung erhalten würden. Mögliche Kategorien seien IPs, Transportports, MAC-Adressen etc. Zudem seien die Daten normalisiert.

Die Klassifikation sei mit fünf verschiedenen Klassifikatoren durchgeführt, somit werde am Ende der performanteste ausgewählt. Die Daten hierfür seien erneut in eine Trainingsmenge und Testmenge unterteilt worden, wobei gelte, dass die zwei Mengen disjunkt seien. Die Klassifikatoren sollen bestmöglich performen. Um dieses zu erreichen, seien die Daten, wie im letzten Absatz erläutert, in die Vorverarbeitung geschickt worden. Zusätzlich seien Hyperparameter optimiert worden. Die Hyperparameter seien in jedem Schritt überprüft und angepasst worden, wobei die 3-fold-cross-validation auf allen Daten verwendet worden sei. Das bedeutet, dass die Daten in drei Mengen aufgeteilt werden. Für jede Kombination seien zwei Mengen als Trainingsdaten verwendet worden und die verbleibende Menge für Testdaten. Als letzte Optimierung seien Korrelationen betrachtet worden.

\subsubsection{Evaluation}

Der Srubber sei mit allen 

\cite{Hohlfeld01}

\section{Source Address Validation}
IP Spoofing, das Versenden von Internetpaketen unter Vortäuschung einer falschen Absenderadresse, stellt ein erhebliches Problem für das Internet dar. Das Fehlen einer Authentifizierung beim Senden von Internetpaketen hat zur Folge, dass es schwierig ist zu identifizieren, ob der angegebene Absender des Pakets wirklich authentisch ist oder ob sich dahinter jemand anderes verbirgt. Die dadurch gewonnene Anonymität wird gezielt ausgenutzt, um verschiedene Arten von Angriffen durchzuführen, darunter insbesondere DDoS Angriffe \cite{Kor01, Gorilla01}. 

Die Notwendigkeit von Authentifizierungsmethoden und Schutzmechanismen gegen IP Spoofing wird immer deutlicher, um die Integrität und Sicherheit des Internets zu gewährleisten. Unternehmen und Organisationen müssen fortlaufend daran arbeiten, effektive Maßnahmen zu implementieren, um sich vor den potenziell verheerenden Auswirkungen von IP Spoofing und den damit verbundenen Angriffen zu schützen.

\subsection{IP Spoofing}
IP Spoofing ist im Kern eine Täuschungstechnik, bei der der Empfänger eines Datenpakets fälschlicherweise glaubt, dass es von einem bestimmten Absender stammt, während es tatsächlich von einem anderen gesendet wurde. Dieser trickreiche Vorgang hat weitreichende Auswirkungen auf die Sicherheit im Netzwerkumfeld und ermöglicht es Angreifern, ihre wahre Identität zu verschleiern.

Technisch betrachtet manipuliert der Angreifer bei IP Spoofing seine IP-Adresse, um sie als die eines anderen Hosts erscheinen zu lassen. Dieser Prozess birgt erhebliche Sicherheitsrisiken, da er es dem Angreifer ermöglicht, sich Zugang zu einem Netzwerk zu verschaffen, ohne entdeckt zu werden. Die fehlende Authentifizierung bei der Übermittlung von Datenpaketen trägt dazu bei, dass der Empfänger diese gefälschten Absenderinformationen nicht zuverlässig überprüfen kann \cite{Beverly01}.


\subsection{Validation}
Bei der Source Address Validation (SAV) ist eine Sicherheitsmaßnahme, die darauf abzielt, IP-Spoofing zu verhindern. Sie besteht darin, dass Netzwerkgeräte wie Router,Firewalls und IXPs überprüfen, ob die Absender IP-Adresse eines eingehenden Datenpakets einer gültigen und erwarteten Adresse entspricht. Das Ziel von SAV ist es sicherzustellen, dass Datenpakete tatsächlich von dem Absender stammt, die er vorgibt zu repräsentieren.

BCP 38 \cite{Ingress01} liefert die erste Möglichkeit um IP-Spoofing zu unterbinden. Um die Mögliechkeit zu implementieren bietet sich die Installation eines sogenannten Ingress-Filters als Maßnahme an. Dieser Filter wird entweder in einem Router oder einer Firewall implementiert. Eine grundlegende Voraussetzung hierfür ist, dass das Netzwerkgerät sämtliche externen Netze kennt, die es mit dem Zentrum verbindet. Das Hauptziel besteht darin, den Internetverkehr zu unterbinden, bevor er das globale Internet erreicht.
Der Ingress-Filter erreicht dieses Ziel, indem er ausschließlich den Verkehr akzeptiert und passieren lässt, der über eine gültige Absenderadresse verfügt. Hierbei ist es entscheidend, dass die Absenderadresse mit den dem Router bekannten IP-Adressen übereinstimmt. Andernfalls wird der Verkehr blockiert und nicht weitergeleitet.
Diese Sicherheitsmaßnahme agiert als eine Früherkennung, um gefälschten Datenverkehr bereits im Ansatz zu eliminieren. Durch die gezielte Überprüfung der Absenderadresse trägt der Ingress-Filter dazu bei, unerwünschten IP-Spoofing-Angriffen effizient entgegenzuwirken und somit die Integrität des Netzwerks zu gewährleisten.



\subsection{Aktueller Stand}

\subsection{Zukunft von SAV}
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.https://de.overleaf.com/project/65760e8888e47700886539c8
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Research Methods}

\subsection{Part One}

TBD


\section{Online Resources}

TBD

\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.

