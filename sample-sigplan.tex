%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]pages
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%

%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan,screen]{acmart}
%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2024}

%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{DDoS defence mechanisims }

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Alexander Haar}
\email{Haaralexander3@gmail.com}
\affiliation{%
  \institution{Universität Kassel}
  \city{Kassel}
  \state{Hessen}
  \country{Deutschland}
}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Abstract TBD
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Source Address Validation, IP Spoofing, IXP, Scrubber, Machine Learning}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Cyberkriminalität ist in der modernen Gesellschaft nicht mehr wegzudenken. Insbesondere die DDoS Attacken gegen Unternehmen und staatliche Institutionen haben in den letzten Jahren dramatisch zugenommen.

\section{IXP Scrubber}
Zuerst wird erklärt was ein Internet Exchange Point (IXP) ist und wo er sich im Internet befindet. Danach erfolgt eine Einführung in den IXP Scrubber, wie er funktioniert und wie er es schafft schädlichen Internetverkehr zu filtern.

\subsection{Internet Exchange Point}
Das Internet besteht aus einer Vielzahl von miteinander verbundenen Netzwerken. Um diese Netzwerke effizient zu verknüpfen, werden sogenannte Internet Exchange Points (IXPs) am Rand dieser platziert. Die IXPs fungieren als zentrale Knotenpunkte im Internet und ermöglichen es, den Internetverkehr von einem Netzwerk auf ein anderes zu leiten. Praktisch betrachtet handele es sich bei IXPs um Schaltstellen, die als Bindeglieder zwischen verschiedenen Netzwerken dienen. Daraus folge, dass durch einen IXP sehr viel Internetverkehr durch laufe.

Die Funktionsweise eines IXPs könne mit der eines Internet-Switches verglichen werden, wobei dieser auf der zweiten Ebene des OSI-Modells positioniert sei. Zur Kommunikation mit einem IXP verwenden Netzwerke das sogenannte Backbone-Protokoll.

Ein wesentlicher Vorteil von einem IXP liege in der geringen Latenz und der kurzen Roundtrip-Zeit. Darüber hinaus ermögliche es ein IXP, den Verkehr im Falle eines Ausfalls auf alternative Routen umzuleiten, was die Robustheit des Netzwerks erhöhe. Dies trage dazu bei, dass das Netzwerk weniger anfällig für Fehler und Störungen sei. \cite{ixp00}

\subsection{IXP Scrubber}
Der IXP Scrubber, im Folgenden als "Scrubber" bezeichnet, werde innerhalb eines Internet Exchange Points (IXP) eingesetzt. Seine Hauptaufgabe sei es, bösartigen Internetverkehr zu erkennen und herauszufiltern. Der Scrubber basiere auf einem Machine Learning System (MLS). Die primäre Motivation hinter diesem Scrubber sei die Abwehr von Distributed Denial of Service (DDoS) Attacken. DDoS Attacken seien besonders problematisch, da es Unternehmen gebe, bei denen der Kauf von Internetverkehr kostengünstig sei. Dies führe dazu, dass dieser Angriffsvektor häufig genutzt werde und das Volumen solcher Angriffe könne bis zu 3,5 Tbit/s erreichen.

Das MLS des Scrubbers bestünde aus zwei Hauptschritten. Zunächst erfolge das Training des Systems, gefolgt von der eigentlichen Klassifizierung der Daten. Der Grundgedanke des Scrubbers sei es, präzise zu arbeiten und gleichzeitig die Übersichtlichkeit zu wahren. Im Anschluss werde der Scrubber evaluiert.

\subsubsection{Microscopic Level}
Um zuverlässig zu funktionieren, brauche das Machine Learning System (MLS) viele Trainingsdaten. Aus diesem Grund seien dem MLS von fünf Partner Internet Exchange Points (IXPs) in Europa und den USA Daten zur Verfügung gestellt worden, die bis zu zwei Jahre alt sein konnten. Diese Daten seien in gutartigen und bösartigen Verkehr unterteilt. Der Internetverkehr, der automatisch vom System oder von benachbarten IXPs manuell als schädlich gekennzeichnet worden sei, erhielt das Label "blackholed". Verkehr mit diesem Label sei in ein "Schwarzes Loch" geleitet worden, was dazu geführt habe, dass sie verschwanden und das Ziel nicht beeinträchtigt worden sei. Durch die Verwendung des Border Gateway Protocol (BGP) seien diese Labels an andere IXPs weitergegeben worden. \cite{blackhole00}
Daten, die dieses Label nicht erhalten haben, seien als gutartig eingestuft worden. Die Trainingsmenge sei aus ungefähr dem gleichen Prozentsatz aus gutartigem und bösartigem Verkehr zusammengesetzt.

Auf den Trainingsdaten sei der Association Rule Mining (ARM) Algorithmus angewandt worden. ARM ist ein bekanntes Data-Mining-Verfahren, das Association-Regeln anhand der Daten in der Form A -> C lernt. Die Anwendung des Verfahrens auf den Testdaten habe 7859 Regeln ergeben. Anschließend seien alle Regeln eliminiert worden, die keinen Mehrwert hatten, weil sie eine zu geringe Konfidenz aufgewiesen hätten. Nach dieser Minimierung seien 367 Regeln übrig geblieben. Diese Anzahl sei gering genug gewesen, um es zu ermöglichen, die Regeln manuell zu überprüfen. In einem User Interface (UI) werden die Regeln angezeigt und Administratoren können zu den Regeln Kommentare hinzufügen sowie diese akzeptieren oder ablehnen.
Die zuvor gewonnen Regeln seien im nächsten Schritt unabhängig geprüft worden, damit überprüft werden konnte, dass sie keine Voreingenommenheit aufweisen und akkurat seien. Hierfür sei eine neue Testmenge erstellt worden, die als "Self Attack Set" (SAS) bezeichnet wurde. Das Wichtige bei diesen Testdaten sei es zu wissen, ob sie wahr oder falsch seien. Um dies zu garantieren, seien DDoS Attacken bei einem Unternehmen, wie Anfangs beschrieben, gekauft und auf einem speziell dafür ausgelegten und abgegrenzten Internetbereich ausgeführt worden. Zusätzlich sei gutartiger Internetverkehr ebenfalls simuliert und der SAS hinzugefügt worden.


In einem zusätzlichen Experiment, sei der ARM Algorithmus auf dem SAS ausgeführt worden. Die gewonnen Regeln seien von fünf Experten ausgewertet worden. Nach der Überprüfung seien 38 Regeln übrig geblieben. Im Anschluss sei gemessen worden, wie lange die Regeln benötigt haben und wie effektiv sie waren. Die Regeln haben eine kurze Laufzeit aufgewiesen und zeigten dabei eine hohe Effizienz auf. Es sei unter einem Prozent gutartiger Verkehr als bösartiger Verkehr gekennzeichnet und 75 Prozent des DDoS Verkehrs erfolgreich erkannt worden. Die Ergebnisse zeigen, dass der Ansatz eine gute Durchführbarkeit besitze.

\subsubsection{Microscopic Level}
Das Ziel des zweiten Schrittes sei es korrekt zu identifizieren, ob ein Ziel angegriffen werde oder nicht. Zusätzliche solle gelten, dass die Identifizierung ortsunabhängig sei und übersichtlich bleibe. Um dieses Ziel zu erreichen werden Kategorien gewichtet. Die Gewichtung finde vor der Klassifikation in der Vorverarbeitung statt. Kategorien, die häufig in blackhole Labels auftreten, würden eine positive Gewichtung erhalten, während Kategorien, die nicht in blackhole Labels auftreten, eine negative Gewichtung erhalten würden. Mögliche Kategorien seien IPs, Transportports, MAC-Adressen etc. Zudem seien die Daten normalisiert.

Die Klassifikation sei mit fünf verschiedenen Klassifikatoren durchgeführt, somit werde am Ende der performanteste ausgewählt. Die Daten hierfür seien erneut in eine Trainingsmenge und Testmenge unterteilt worden, wobei gelte, dass die zwei Mengen disjunkt seien. Die Klassifikatoren sollen bestmöglich performen. Um dieses zu erreichen, seien die Daten, wie im letzten Absatz erläutert, in die Vorverarbeitung geschickt worden. Zusätzlich seien Hyperparameter optimiert worden. Die Hyperparameter seien in jedem Schritt überprüft und angepasst worden, wobei die 3-fold-cross-validation auf allen Daten verwendet worden sei. Das bedeutet, dass die Daten in drei Mengen aufgeteilt werden. Für jede Kombination seien zwei Mengen als Trainingsdaten verwendet worden und die verbleibende Menge für Testdaten. Als letzte Optimierung seien Korrelationen betrachtet worden.

\subsubsection{Evaluation}

Der Srubber sei mit allen 

\cite{Hohlfeld01}

\section{Source Address Validation}
IP Spoofing, das Versenden von Internetpaketen unter Vortäuschung einer falschen Absenderadresse, stellt ein erhebliches Problem für das Internet dar. Das Fehlen einer Authentifizierung beim Senden von Internetpaketen hat zur Folge, dass es schwierig ist zu identifizieren, ob der angegebene Absender des Pakets wirklich authentisch ist oder ob sich dahinter jemand anderes verbirgt. Die dadurch gewonnene Anonymität wird gezielt ausgenutzt, um verschiedene Arten von Angriffen durchzuführen, darunter insbesondere DDoS Angriffe \cite{Kor01, Gorilla01}. 

Die Notwendigkeit von Authentifizierungsmethoden und Schutzmechanismen gegen IP Spoofing wird immer deutlicher, um die Integrität und Sicherheit des Internets zu gewährleisten. Unternehmen und Organisationen müssen fortlaufend daran arbeiten, effektive Maßnahmen zu implementieren, um sich vor den potenziell verheerenden Auswirkungen von IP Spoofing und den damit verbundenen Angriffen zu schützen.

\subsection{IP Spoofing}
IP Spoofing ist im Kern eine Täuschungstechnik, bei der der Empfänger eines Datenpakets fälschlicherweise glaubt, dass es von einem bestimmten Absender stammt, während es tatsächlich von einem anderen gesendet wurde. Dieser trickreiche Vorgang hat weitreichende Auswirkungen auf die Sicherheit im Netzwerkumfeld und ermöglicht es Angreifern, ihre wahre Identität zu verschleiern.

Technisch betrachtet manipuliert der Angreifer bei IP Spoofing seine IP-Adresse, um sie als die eines anderen Hosts erscheinen zu lassen. Dieser Prozess birgt erhebliche Sicherheitsrisiken, da er es dem Angreifer ermöglicht, verschiedene Angriffe auf ein Ziel auszuüben. Die fehlende Authentifizierung bei der Übermittlung von Datenpaketen trägt dazu bei, dass der Empfänger diese gefälschten Absenderinformationen nicht zuverlässig überprüfen kann \cite{Beverly01}.

Diese Täuschungstechnik besteht bereits seit mehr als 25 Jahren und hat sich in dieser Zeit als beliebt für Anonymität und verschiedene DDoS-Angriffsvektoren wie Redirection und Amplification etabliert \cite{manrs01}.

\subsection{Validation}
Source Address Validation (SAV) fungiert als Schutzmaßnahme gegen IP-Spoofing. Die Hauptabsicht von SAV besteht darin, die Echtheit der Absenderadresse eines Datenpakets zu überprüfen. In der aktuellen Internetarchitektur fehlt eine Authentifizierungsoption beim Senden von Datenpaketen. Diese Sicherheitslücke ermöglicht IP-Spoofing, was wiederum zu einer Zunahme von DDoS-Angriffen führt \cite{Hal01}.

\subsubsection{oSAV und iSAV: Schlüsselrolle in der Netzwerksicherheit}
Je nachdem, in welche Richtung des Internetflusses der SAV eingesetzt wird, erfüllt er unterschiedliche Funktionen und Ziele. Outbound SAV (oSAV) prüft die Echtheit der Absenderadressen, wenn Datenpakete das interne Netzwerk verlassen, während Inbound SAV (iSAV) die Absenderadressenüberprüfung für eingehende Datenpakete aus dem externen Netzwerk durchführt. Diese Unterscheidung ist entscheidend für die Implementierung von Sicherheitsmaßnahmen und die Reduzierung von Angriffsvektoren in beide Richtungen des Datenverkehrs \cite{Hal01}.

Die Nichtumsetzung von oSAV erleichtert Angreifern insbesondere die Durchführung von DDoS-Angriffen, insbesondere Reflection-Angriffen über das offene Domain Name System (DNS) oder das Network Time Protocol (NTP). Bei diesen Angriffen nutzen Angreifer öffentliche Server, um Schaden anzurichten, indem sie manipulierte IP-Adressen verwenden, um Anfragen zu senden und den Empfänger mit übermäßigen Antworten zu überlasten. Zudem erhält der „Absender“ ebenfalls Antworten aufgrund des Transmission Control Protocol (TCP) Handshake. Darüber hinaus bleibt der Angreifer aufgrund der fehlenden Identifikation unerkannt \cite{manrs01} \cite{Hal01} \cite{Ingress01}. Bei fehlendem iSAV zusammen mit neuen Attacken wie Water Torture Attack (Lou et al \cite{Lou01}) könnte zu erheblichen Konsequenzen führen.

\textbf{//TODO Figure oSAV und iSAV}

\subsubsection{Ingress Filter}
In den 1990er Jahren wurden die ersten DDoS-Angriffe öffentlich bekannt, die auf IP-Spoofing basierten \cite{CRP01}. Die daraus resultierende Unsicherheit und die Befürchtung, wenig dagegen unternehmen zu können, führten dazu, dass Fergusan et al. (BCP 38) \cite{Ingress01} im Jahr 2000 den sogenannten "Ingress Filter" vorstellten. Dieser sollte dazu dienen, die Auswirkungen von IP-Spoofing und den daraus resultierenden DDoS-Angriffen zu minimieren. Dieser Filter setzt voraus, dass eine Liste aller gültigen IP-Prefixe vorhanden ist. Seine Funktionsweise besteht darin, IP-Spoofing-Angriffe zu unterbinden, indem er nur den Datenverkehr passieren lässt, dessen IP-Prefix in seiner Liste aufgeführt ist. Falls der Prefix nicht aufgeführt ist, wird der Datenverkehr blockiert. Um einen erfolgreichen Angriff zu starten, muss ein Angreifer eine gültige IP-Adresse aus seinem regionalen Bereich übernehmen, um den Filter zu umgehen.

Ein Nachteil dieses Ansatzes besteht darin, dass die IP-Adresse möglicherweise von einem Internetdienstanbieter (ISP) blockiert wird. Dies könnte dazu führen, dass der legitime Sender Schaden erleidet, obwohl er nichts mit dem Angriff zu tun hat. Andererseits bietet der Filter den Vorteil, dass Angreifer aufgrund der regionalen Einschränkung einfacher identifiziert werden können. Zusätzlich profitieren Unternehmen von einem verbesserten Schutz, da sie einem geringeren Risiko für DDoS-Angriffe ausgesetzt sind.

Es wird dringend empfohlen, dass Internetdienstanbieter und andere Netzwerkadministratoren den Ingress Filter an den Rändern ihrer Netzwerke implementieren, um das Problem effektiv anzugehen. Netzwerke, die auf diesen Filter verzichten, unterstützen potenzielle Angreifer und tragen somit zu der Problematik bei.

\subsubsection{Erweiterung des Ingress Filters}
Der zuvor präsentierte Filter weist einige Schwächen auf. Insbesondere kann es dazu kommen, dass der Internetverkehr blockiert wird, obwohl er legitim ist, weil zum Beispiel die Liste der IP-Prefixe nicht auf dem neuesten Stand ist. Um diesem Problem zu einzudämmen, stellen Fergusan et al. (BCP 84) \cite{Bcp84} vier Jahre später für den Filter Alternativen um ihn zu implementieren vor. Eine Alternative ist es statische Acces Controll Lists (ACLs) zu benutzen. Ein weiterer ist Strict Reverse Path Forwarding (Strict RPF). Hierbei wird die Quelladresse eines Pakets im Forwarding Information Base (FIB) überprüft. Die Überprüfung erfolgt erfolgreich, wenn das Paket über die Schnittstelle empfangen wird, die normalerweise für die Weiterleitung zum Ursprungsort des Pakets verwendet wird. BCP 38 und BCP 84 gelten als "Best Practice" \cite{Hal01}.

\subsection{Aktueller Stand von SAV}
IP-Spoofing und die daraus resultierende DdoS-Angriffe existieren bereits länger als 25 Jahre \cite{manrs01}. Obwohl vor 25 Jahren das Internet noch nicht die Relevanz wie heutzutage hat, waren die Angriffe ein Problem. Der 2000 vorgestellte „Ingress Filter“ \cite{Ingress01} und die 2004 Erweiterung des Filters \cite{BCP78} gelten aktuell immer noch als Best Practice \cite{CRP01} \cite{Lone01} \cite{Hal01} \cite{manrs01}.  

\subsubsection{Spoofer Project}
Robert Beverly et al. \cite{Spoofer01} haben 2005 den ersten Versuch unternommen, das Internet in Bezug auf SAV zu messen, und ihre Ergebnisse im sogenannten Spoofer Project vorgestellt. Im Rahmen des Projekts wurden Freiwillige gesucht, die eine Software installierten, um das Netzwerk, an das ihre Computer angeschlossen waren, auf SAV zu überprüfen. Die Software sandte regelmäßig Anfragen mit sowohl verfälschten als auch nicht verfälschten IP-Adressen an einen bestimmten Server. Dieser Server überprüfte die empfangenen Anfragen und analysierte, ob Spoofing erlaubt war. Die gewonnenen Daten wurden öffentlich im Internet zugänglich gemacht. Ein Vorteil dieser Messungen besteht darin, dass sie nicht nur Netzwerke aufdecken, die IP-Spoofing erlauben, sondern auch solche, die es nicht erlauben. Ein Nachteil des Projekts ist jedoch, dass Daten nur gewonnen werden können, wenn es Freiwillige gibt, die sie sammeln. Dadurch herrscht eine unabsichtliche Auswahlverzerrung in den Regionen von ISPs in denen es mehr Nutzer gibt. Zusätzlich sind einige ISPs unterrepräsentiert oder gar nicht vertreten in Regionen, wo das Projekt keine Bekanntheit hat. Darüber hinaus werden Netzwerke, die bewusst auf SAV verzichten, nicht freiwillig an solchen Messungen teilnehmen.

\subsection{Zukunft von SAV}
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.https://de.overleaf.com/project/65760e8888e47700886539c8
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Research Methods}

\subsection{Part One}

TBD


\section{Online Resources}

TBD

\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.

